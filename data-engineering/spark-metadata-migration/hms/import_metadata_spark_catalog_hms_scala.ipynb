{"cells":[{"cell_type":"code","execution_count":1,"id":"6f71db72-a0e4-4953-83b7-60d378cd6696","metadata":{"microsoft":{"language":"scala"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T10:59:34.8921246Z","execution_start_time":"2023-09-26T10:59:31.9852799Z","livy_statement_state":"available","parent_msg_id":"37965ce7-b9ca-401f-85d4-d5d5ea0302c0","queued_time":"2023-09-26T10:59:21.2716671Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":"2023-09-26T10:59:21.4456036Z","spark_jobs":{"jobs":[],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":3},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 3, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["WorkspaceId: String = d3de3f63-266f-454c-87e1-5c7c598a41dd\n","LakehouseId: String = 255fdd58-6a1d-40b6-86f7-76102aab0fbd\n","IntermediateFolderPath: String = abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/hms_output/syn/\n","ContainerName: String = default\n","StorageName: String = stmurggudata\n","WarehouseMappings: Map[String,String] = Map(abfss://default@stmurggudata.dfs.core.windows.net/synapse/workspaces/syn-murggu-hms/warehouse -> abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/warehouse_dir_syn, dbfs:/mnt/stmurggudata/databricks/warehouse -> abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/warehouse_dir_dbx, abfss://default@stmurggudata.dfs.core.windows.net/apps/spark/warehouse -> abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/warehouse_dir_hdi)\n","DatabasePrefix: String = \"\"\n","TablePrefix: String = \"\"\n","IgnoreIfExists: Boolean = true\n"]}],"source":["%%spark\n","// Fabric config\n","var WorkspaceId = \"<workspace_id>\"\n","var LakehouseId = \"<lakehouse_id>\"\n","var IntermediateFolderPath = f\"abfss://${WorkspaceId}@onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/hms_output/syn/\"\n","\n","var ContainerName = \"<container_name>\"\n","var StorageName = \"<storage_name>\"\n","var SynapseWorkspaceName = <synapse_workspace_name>\n","var WarehouseMappings:Map[String, String] = Map(\n","    f\"abfss://${ContainerName}@${StorageName}.dfs.core.windows.net/synapse/workspaces/${SynapseWorkspaceName}/warehouse\"-> f\"abfss://${WorkspaceId}@onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/warehouse_dir_syn\",\n","    f\"dbfs:/mnt/${StorageName}/databricks/warehouse\"->f\"abfss://${WorkspaceId}@onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/warehouse_dir_dbx\",\n","    f\"abfss://${ContainerName}@${StorageName}.dfs.core.windows.net/apps/spark/warehouse\"->f\"abfss://${WorkspaceId}@onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/warehouse_dir_hdi\"\n",")\n","\n","// Metastore config\n","var DatabasePrefix = \"\"\n","var TablePrefix = \"\"\n","var IgnoreIfExists = true"]},{"cell_type":"code","execution_count":4,"id":"347ad4ed-313b-4836-9b8f-1a0125b00376","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T11:02:59.883597Z","execution_start_time":"2023-09-26T11:02:48.6880099Z","livy_statement_state":"available","parent_msg_id":"c2d81b05-898a-4d3d-b97f-672f9e12bcde","queued_time":"2023-09-26T11:02:48.3445276Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-26T11:02:57.988GMT","dataRead":682,"dataWritten":0,"description":"Job group for statement 6:\nimport java.net.URI\nimport java.util.Calendar\n\nimport scala.collection.mutable.{ListBuffer, Map}\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{ObjectType, _}\nimport org.apache.spark.sql.catalyst._\nimport org.apache.spark.sql.catalyst.catalog._\nimport org.json4s._\nimport org.json4s.JsonAST.JString\nimport org.json4s.jackson.Serialization\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.{FileSystem, Path}\nimport org.apache.http.client.methods.{CloseableHttpResponse, HttpPost}\nimport org.apache.http.entity.StringEntity\nimport org.apache.http.impl.client.{CloseableHttpClient, HttpClients}\nimport scala.io.Source\n\n\nvar locationPrefixMappingList = WarehouseMappings.toList.sortBy(pair => pair._1).reverse\n\nval DatabaseType = \"database\"\nval TableType = \"table\"\nval PartitionType = \"partition\"\n\nobject ImportMetadata {\n\n  val spark = SparkSession.builder().getOrCreate()\n\n  case object URISerializer extends CustomSerializer[URI](format => ( {\n    case JString(uri) => new URI(uri)\n  ...","displayName":"collect at <console>:391","jobGroup":"6","jobId":8,"killedTasksSummary":{},"name":"collect at <console>:391","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":5,"numCompletedStages":1,"numCompletedTasks":5,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":5,"rowCount":10,"stageIds":[12],"status":"SUCCEEDED","submissionTime":"2023-09-26T11:02:56.808GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":6},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 6, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to load stats Tue Sep 26 11:02:53 UTC 2023\n","import java.net.URI\n","import java.util.Calendar\n","import scala.collection.mutable.{ListBuffer, Map}\n","import org.apache.spark.sql._\n","import org.apache.spark.sql.types.{ObjectType, _}\n","import org.apache.spark.sql.catalyst._\n","import org.apache.spark.sql.catalyst.catalog._\n","import org.json4s._\n","import org.json4s.JsonAST.JString\n","import org.json4s.jackson.Serialization\n","import org.apache.hadoop.conf.Configuration\n","import org.apache.hadoop.fs.{FileSystem, Path}\n","import org.apache.http.client.methods.{CloseableHttpResponse, HttpPost}\n","import org.apache.http.entity.StringEntity\n","import org.apache.http.impl.client.{CloseableHttpClient, HttpClients}\n","import scala.io.Source\n","locationPrefixMappingList: List[(String, String)] = List((dbfs:/mnt/stmurggudata/databricks/warehouse,abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/warehouse_dir_dbx), (abfss://default@stmurggudata.dfs.core.windows.net/synapse/workspaces/syn-murggu-hms/warehouse,abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/warehouse_dir_syn), (abfss://default@stmurggudata.dfs.core.windows.net/apps/spark/warehouse,abfss://d3de3f63-266f-454c-87e1-5c7c598a41dd@onelake.dfs.fabric.microsoft.com/255fdd58-6a1d-40b6-86f7-76102aab0fbd/Files/warehouse_dir_hdi))\n","DatabaseType: String = database\n","TableType: String = table\n","PartitionType: String = partition\n","warning: one deprecation (since 2.11.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n","defined object ImportMetadata\n","stats: List[ImportMetadata.CatalogStat] = List(CatalogStat(partition,2,Some(syndb1),Some(t_unmanag_part_parquet)), CatalogStat(partition,2,Some(syndb1),Some(t_manag_part_parquet)), CatalogStat(partition,2,Some(syndb1),Some(t_unmanag_part_json)), CatalogStat(partition,2,Some(syndb1),Some(t_unmanag_part_csv)), CatalogStat(partition,2,Some(syndb1),Some(t_manag_part_json)), CatalogStat(partition,2,Some(syndb1),Some(t_manag_part_csv)), CatalogStat(table,16,Some(syndb1),None), CatalogStat(partition,12,None,None), CatalogStat(database,1,None,None), CatalogStat(table,16,None,None))\n"]}],"source":["%%spark\n","import java.net.URI\n","import java.util.Calendar\n","\n","import scala.collection.mutable.{ListBuffer, Map}\n","import org.apache.spark.sql._\n","import org.apache.spark.sql.types.{ObjectType, _}\n","import org.apache.spark.sql.catalyst._\n","import org.apache.spark.sql.catalyst.catalog._\n","import org.json4s._\n","import org.json4s.JsonAST.JString\n","import org.json4s.jackson.Serialization\n","import org.apache.hadoop.conf.Configuration\n","import org.apache.hadoop.fs.{FileSystem, Path}\n","import org.apache.http.client.methods.{CloseableHttpResponse, HttpPost}\n","import org.apache.http.entity.StringEntity\n","import org.apache.http.impl.client.{CloseableHttpClient, HttpClients}\n","import scala.io.Source\n","\n","\n","var locationPrefixMappingList = WarehouseMappings.toList.sortBy(pair => pair._1).reverse\n","\n","val DatabaseType = \"database\"\n","val TableType = \"table\"\n","val PartitionType = \"partition\"\n","\n","object ImportMetadata {\n","\n","  val spark = SparkSession.builder().getOrCreate()\n","\n","  case object URISerializer extends CustomSerializer[URI](format => ( {\n","    case JString(uri) => new URI(uri)\n","  }, {\n","    case uri: URI => JString(uri.toString())\n","  }))\n","\n","  case object SturctTypeSerializer extends CustomSerializer[StructType](format => ( {\n","    case JString(structType)  => DataType.fromJson(structType).asInstanceOf[StructType]\n","  }, {\n","    case structType: StructType => JString(structType.json)\n","  }))\n","\n","\n","  implicit val formats = DefaultFormats + URISerializer + SturctTypeSerializer\n","\n","  case class CatalogPartitions(database: String, table: String, tablePartitons: Seq[CatalogTablePartition])\n","\n","  case class CatalogTables(database: String, tables: Seq[CatalogTable])\n","\n","  case class CatalogStat(entityType: String, count: Int, database: Option[String], table: Option[String])\n","\n","  def ConvertLocation(location: String) : String = {\n","    var locationMapping = locationPrefixMappingList.find(mapping => {location.startsWith(mapping._1)})\n","\n","    if (locationMapping != None) {\n","      return location.replaceFirst(locationMapping.get._1, locationMapping.get._2)\n","    }\n","\n","    return location;\n","  }\n","\n","  def ConvertCatalogDatabase(database: CatalogDatabase) : CatalogDatabase = {\n","    var convertedDatabase  = new CatalogDatabase(\n","      DatabasePrefix + database.name,\n","      database.description,\n","      new URI(ConvertLocation(database.locationUri.toString())),\n","      database.properties)\n","\n","    return convertedDatabase;\n","  }\n","\n","  def ConvertCatalogStorageFormat(format : CatalogStorageFormat) : CatalogStorageFormat = {\n","\n","    var formatlocation: Option[URI] = None\n","    if (format.locationUri != None) {\n","      formatlocation = Some(new URI(ConvertLocation(format.locationUri.get.toString())))\n","    }\n","\n","    var convertedStorageFormat = new CatalogStorageFormat(\n","      formatlocation,\n","      format.inputFormat,\n","      format.outputFormat,\n","      format.serde,\n","      format.compressed,\n","      format.properties\n","    )\n","\n","    return  convertedStorageFormat;\n","  }\n","\n","  def ConvertCatalogTable(table: CatalogTable) : CatalogTable = {\n","\n","    var dbName = Some(DatabasePrefix + table.identifier.database.get);\n","    var tblName = TablePrefix + table.identifier.table;\n","\n","    var convertedTable = new CatalogTable(\n","      new TableIdentifier(tblName, dbName),\n","      org.apache.spark.sql.catalyst.catalog.CatalogTableType(\"EXTERNAL\"),\n","      ConvertCatalogStorageFormat(table.storage),\n","      table.schema,\n","      table.provider,\n","      table.partitionColumnNames,\n","      table.bucketSpec,\n","      table.owner,\n","      table.createTime,\n","      table.lastAccessTime,\n","      table.createVersion,\n","      table.properties,\n","      table.stats,\n","      table.viewText,\n","      table.comment,\n","      table.unsupportedFeatures,\n","      table.tracksPartitionsInCatalog,\n","      table.schemaPreservesCase,\n","      table.ignoredProperties)\n","\n","    return convertedTable;\n","  }\n","\n","  def ConvertCatalogTablePartition(partition : CatalogTablePartition) : CatalogTablePartition = {\n","    var convertedPartition = new CatalogTablePartition(\n","      partition.spec,\n","      ConvertCatalogStorageFormat(partition.storage),\n","      partition.parameters,\n","      partition.createTime,\n","      partition.lastAccessTime,\n","      partition.stats\n","    );\n","\n","    return convertedPartition;\n","  }\n","\n","  val MaxRetryCount = 3;\n","\n","  def RetriableFunc(func: () => Unit, retryCount: Int = 0): Unit = {\n","    try {\n","      func()\n","    } catch {\n","      case e:Exception => {\n","        if (retryCount < MaxRetryCount){\n","          RetriableFunc(func, retryCount + 1)\n","        } else {\n","          throw e\n","        }\n","      }\n","    }\n","  }\n","\n","  def RetriableQueryFunc(func: () => Object, retryCount: Int = 0): Object = {\n","    try {\n","      func()\n","    } catch {\n","      case e:Exception => {\n","        if (retryCount < MaxRetryCount){\n","          RetriableQueryFunc(func, retryCount + 1)\n","        } else {\n","          throw e\n","        }\n","      }\n","    }\n","  }\n","\n","// Create DBs\n","\n","  def CreateDatabases(dataPath: String): Int = {\n","\n","    println(\"Start to create databases \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath)\n","\n","    var createdCount = 0;\n","    var existsDbs = spark.sharedState.externalCatalog.listDatabases()\n","    var data = ds.collect()\n","    var total = data.size\n","\n","    data.foreach(row => {\n","      var jsonString = row.getString(0)\n","      var newDb = ConvertCatalogDatabase(Serialization.read[CatalogDatabase](jsonString))\n","\n","      var exists = existsDbs.contains(newDb.name)\n","      if (exists && !IgnoreIfExists) {\n","\n","        println(createdCount + \"/\" + total + \" databases created. \" + Calendar.getInstance().getTime())\n","        println(\"Database \" + newDb.name + \" already exists\")\n","\n","        throw new Exception(\"Database \" + newDb.name + \" already exists\")\n","      } else if (!exists) {\n","        CreateDatabase(newDb.name)\n","      }\n","\n","      createdCount+=1;\n","\n","      if (createdCount%100 == 0) {\n","        println(createdCount + \"/\" + total + \" databases created\" + Calendar.getInstance().getTime())\n","      }\n","    });\n","\n","    println(\"Databases Created completed. Total \" + createdCount + \" database created. \" + Calendar.getInstance().getTime())\n","    return createdCount\n","  }\n","\n","  def CreateDatabase(dbName: String) = {\n","    mssparkutils.lakehouse.create(dbName, \"imported db\", WorkspaceId)\n","  }\n","\n","  // Create Tables\n","\n","  def CreateTables(dataPath: String): Int = {\n","    println(\"Start to create tables \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath);\n","\n","    var createdCount = 0;\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      var tables = Serialization.read[CatalogTables](jsonString);\n","\n","      var existsTables = spark.sharedState.externalCatalog.listTables(DatabasePrefix + tables.database)\n","      var perTables = tables.tables.toParArray\n","\n","      perTables.foreach(table => {\n","        var newTable = ConvertCatalogTable(table)\n","        var exists = existsTables.contains(newTable.identifier.table)\n","        if (exists && !IgnoreIfExists) {\n","\n","          println(createdCount + \" tables created. \" + Calendar.getInstance().getTime())\n","          println(\"Table \" + newTable.identifier.database + \".\" + newTable.identifier.table + \" already exists\")\n","\n","          throw new Exception(\"Table \" + newTable.identifier.database + \".\" + newTable.identifier.table + \" already exists\")\n","        } else if (!exists) {\n","          CreateTable(newTable)\n","        }\n","\n","        createdCount+=1;\n","      })\n","\n","      println(createdCount + \" tables created\" + Calendar.getInstance().getTime())\n","    })\n","\n","    println(\"Tables Created completed. Total \" + createdCount + \" table created. \" + Calendar.getInstance().getTime())\n","    return createdCount\n","  }\n","\n","  def CreateTable(table:CatalogTable) = {\n","    RetriableFunc(() => {\n","      spark.sharedState.externalCatalog.createTable(table, IgnoreIfExists)\n","    })\n","  }\n","\n","  def ValidateTablePath(dataPath: String) = {\n","    println(\"Start to validate table path \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath)\n","    var hadoopConf = spark.sparkContext.hadoopConfiguration\n","\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      var tables = Serialization.read[CatalogTables](jsonString);\n","\n","      tables.tables.toParArray.foreach(table => {\n","        var newTable = ConvertCatalogTable(table)\n","        try{\n","          var p = new Path(newTable.location);\n","          var fs = p.getFileSystem(hadoopConf);\n","        } catch {\n","          case e:Exception => {\n","            throw new Exception(\"Validate table path failed. Table: \" + newTable.identifier.database.getOrElse() + \".\" + newTable.identifier.table + \", Location: \" +  newTable.location + \" , exception: \" + e)\n","          }\n","        }\n","      })\n","    })\n","\n","    println(\"Validate table path completed\")\n","  }\n","\n","  // Create Partitions\n","\n","  def CreatePartitions(dataPath: String): Int = {\n","    println(\"Start to create partitions \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath);\n","\n","    var createdCount = 0;\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      var parts = Serialization.read[CatalogPartitions](jsonString);\n","\n","      var catalogTablePartitions = new ListBuffer[CatalogTablePartition]()\n","      parts.tablePartitons.foreach( part => {\n","        catalogTablePartitions += ConvertCatalogTablePartition(part)\n","      })\n","\n","      RetriableFunc(() => {\n","        spark.sharedState.externalCatalog.createPartitions(DatabasePrefix + parts.database, TablePrefix + parts.table, catalogTablePartitions, IgnoreIfExists)\n","      })\n","\n","      createdCount+=catalogTablePartitions.size;\n","      println(createdCount +  \" partitions created\" + Calendar.getInstance().getTime())\n","    });\n","\n","    println(\"Partition Created completed. Total \" + createdCount + \" partition created. \" + Calendar.getInstance().getTime())\n","    return createdCount\n","  }\n","\n","  def LoadStats(dataPath: String): List[CatalogStat] = {\n","    println(\"Start to load stats \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath);\n","\n","    var statBuffer = new ListBuffer[CatalogStat];\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      statBuffer.append(Serialization.read[CatalogStat](jsonString))\n","    })\n","\n","    return statBuffer.toList\n","  }\n","\n","  def ValidateImportResult(entityType: String, createdCount: Int, stats: List[CatalogStat]):Boolean = {\n","    var mappingStat = stats.find(stat => stat.entityType == entityType && stat.database == None && stat.table == None);\n","    if (mappingStat == None) {\n","      println(\"Validated failed. Failed to get orignal \" + entityType + \" count\")\n","      return false\n","    }\n","\n","    if (mappingStat.get.count != createdCount) {\n","      println(\"Validated failed. Catalog object count missmatch. Expected \" + entityType + \" count is \" + mappingStat.get.count + \", but created \" + entityType + \" count is \" + createdCount);\n","      return false;\n","    }\n","\n","    println(\"Validated passed. Catalog objects are created as expected. \" + createdCount + \" \" + entityType + \" are created.\" )\n","    return true\n","  }\n","\n","  def ImportCatalogObjectsFromFile(inputPath: String) = {\n","\n","    val dbsPath = inputPath + \"databases\";\n","    val tablesPath = inputPath + \"tables\";\n","    val partPath = inputPath + \"partitions\";\n","\n","    CreateDatabases(dbsPath)\n","    CreateTables(tablesPath)\n","    CreatePartitions(partPath)\n","  }\n","}\n","\n","var stats = ImportMetadata.LoadStats(IntermediateFolderPath + \"/catalogObjectStats\")"]},{"cell_type":"code","execution_count":5,"id":"482efd6b-1866-42e0-b37b-7101b9d1d64e","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T11:03:11.1563757Z","execution_start_time":"2023-09-26T11:03:06.9486481Z","livy_statement_state":"available","parent_msg_id":"cefed6d9-d6c0-4243-acd6-bf3fa6f0eff7","queued_time":"2023-09-26T11:03:06.6235962Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-26T11:03:09.568GMT","dataRead":23578,"dataWritten":0,"description":"Job group for statement 7:\n// Validate table path\nImportMetadata.ValidateTablePath(IntermediateFolderPath + \"/tables\")","displayName":"collect at <console>:336","jobGroup":"7","jobId":9,"killedTasksSummary":{},"name":"collect at <console>:336","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":1,"stageIds":[13],"status":"SUCCEEDED","submissionTime":"2023-09-26T11:03:08.861GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":7},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 7, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to validate table path Tue Sep 26 11:03:07 UTC 2023\n","Validate table path completed\n"]}],"source":["%%spark\n","// Validate table path\n","ImportMetadata.ValidateTablePath(IntermediateFolderPath + \"/tables\")"]},{"cell_type":"code","execution_count":6,"id":"29ca55a3-88fd-4b98-80b2-2654b3df13f3","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T11:03:33.6582495Z","execution_start_time":"2023-09-26T11:03:15.8619625Z","livy_statement_state":"available","parent_msg_id":"1edb0b56-8053-4953-b37c-aabfd89f9960","queued_time":"2023-09-26T11:03:15.5550638Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-26T11:03:29.404GMT","dataRead":202,"dataWritten":0,"description":"Job group for statement 8:\n// Import Databases\nvar createdDb = ImportMetadata.CreateDatabases(IntermediateFolderPath + \"/databases\")\nImportMetadata.ValidateImportResult(DatabaseType, createdDb, stats)","displayName":"collect at <console>:253","jobGroup":"8","jobId":10,"killedTasksSummary":{},"name":"collect at <console>:253","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":1,"stageIds":[14],"status":"SUCCEEDED","submissionTime":"2023-09-26T11:03:29.191GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":8},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 8, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to create databases Tue Sep 26 11:03:16 UTC 2023\n","Databases Created completed. Total 1 database created. Tue Sep 26 11:03:32 UTC 2023\n","Validated passed. Catalog objects are created as expected. 1 database are created.\n","createdDb: Int = 1\n","res13: Boolean = true\n"]}],"source":["// Import Databases\n","var createdDb = ImportMetadata.CreateDatabases(IntermediateFolderPath + \"/databases\")\n","ImportMetadata.ValidateImportResult(DatabaseType, createdDb, stats)"]},{"cell_type":"code","execution_count":7,"id":"d309fe7d-66ea-45dd-affe-2444c044f555","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T11:03:38.9235468Z","execution_start_time":"2023-09-26T11:03:37.0749989Z","livy_statement_state":"available","parent_msg_id":"ba9be6d0-fe0f-49e7-b9fd-3d08f5a59747","queued_time":"2023-09-26T11:03:36.7436227Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":null,"spark_jobs":{"jobs":[],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":9},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 9, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["res15: Seq[String] = Buffer(synapse, syndb1)\n"]}],"source":["%%spark\n","// Validate Lakehouse (database) creation\n","spark.sharedState.externalCatalog.listDatabases()"]},{"cell_type":"code","execution_count":8,"id":"b43b002a-3926-41c6-9686-8d66b6e776cc","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T11:04:05.252415Z","execution_start_time":"2023-09-26T11:03:42.7536732Z","livy_statement_state":"available","parent_msg_id":"85a6220e-6991-4c20-8ec3-5181166c8e0f","queued_time":"2023-09-26T11:03:42.4419729Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-26T11:03:45.499GMT","dataRead":23578,"dataWritten":0,"description":"Job group for statement 10:\n// Import Tables\nvar createdTbl = ImportMetadata.CreateTables(IntermediateFolderPath + \"/tables\")\nImportMetadata.ValidateImportResult(TableType, createdTbl, stats)","displayName":"collect at <console>:294","jobGroup":"10","jobId":11,"killedTasksSummary":{},"name":"collect at <console>:294","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":1,"stageIds":[15],"status":"SUCCEEDED","submissionTime":"2023-09-26T11:03:45.024GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":10},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 10, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to create tables Tue Sep 26 11:03:43 UTC 2023\n","16 tables createdTue Sep 26 11:04:02 UTC 2023\n","Tables Created completed. Total 16 table created. Tue Sep 26 11:04:02 UTC 2023\n","Validated passed. Catalog objects are created as expected. 16 table are created.\n","createdTbl: Int = 16\n","res17: Boolean = true\n"]}],"source":["%%spark\n","// Import Tables\n","var createdTbl = ImportMetadata.CreateTables(IntermediateFolderPath + \"/tables\")\n","ImportMetadata.ValidateImportResult(TableType, createdTbl, stats)"]},{"cell_type":"code","execution_count":9,"id":"f79e4008-8085-4065-8d27-898ddc2fa106","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-26T11:04:14.5958976Z","execution_start_time":"2023-09-26T11:04:05.5760646Z","livy_statement_state":"available","parent_msg_id":"6ec56e42-257c-494b-bc85-8841c754fe4f","queued_time":"2023-09-26T11:03:45.5509068Z","session_id":"0c0ab054-b220-4fc9-9a59-833c571f737c","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-26T11:04:08.097GMT","dataRead":9372,"dataWritten":0,"description":"Job group for statement 11:\n// Import Partitions\nvar createdPart = ImportMetadata.CreatePartitions(IntermediateFolderPath + \"/partitions\")\nImportMetadata.ValidateImportResult(PartitionType, createdPart, stats)","displayName":"collect at <console>:364","jobGroup":"11","jobId":12,"killedTasksSummary":{},"name":"collect at <console>:364","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":6,"numCompletedStages":1,"numCompletedTasks":6,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":6,"rowCount":6,"stageIds":[16],"status":"SUCCEEDED","submissionTime":"2023-09-26T11:04:07.383GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":11},"text/plain":["StatementMeta(, 0c0ab054-b220-4fc9-9a59-833c571f737c, 11, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to create partitions Tue Sep 26 11:04:06 UTC 2023\n","2 partitions createdTue Sep 26 11:04:09 UTC 2023\n","4 partitions createdTue Sep 26 11:04:10 UTC 2023\n","6 partitions createdTue Sep 26 11:04:10 UTC 2023\n","8 partitions createdTue Sep 26 11:04:11 UTC 2023\n","10 partitions createdTue Sep 26 11:04:12 UTC 2023\n","12 partitions createdTue Sep 26 11:04:12 UTC 2023\n","Partition Created completed. Total 12 partition created. Tue Sep 26 11:04:12 UTC 2023\n","Validated passed. Catalog objects are created as expected. 12 partition are created.\n","createdPart: Int = 12\n","res19: Boolean = true\n"]}],"source":["%%spark\n","// Import Partitions\n","var createdPart = ImportMetadata.CreatePartitions(IntermediateFolderPath + \"/partitions\")\n","ImportMetadata.ValidateImportResult(PartitionType, createdPart, stats)"]},{"cell_type":"code","execution_count":9,"id":"314a2bcc-0f32-49d9-9d0a-0edbe370ceb3","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"sparksql"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-25T14:14:56.8822088Z","execution_start_time":"2023-09-25T14:14:49.7187406Z","livy_statement_state":"available","parent_msg_id":"9ea2a4ee-27fd-4b38-9d62-0b6d40718b1a","queued_time":"2023-09-25T14:14:49.4067212Z","session_id":"10d88e4e-d3dd-415c-93ed-45b9586d38ca","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-25T14:14:53.990GMT","dataRead":4469,"dataWritten":0,"description":"Delta: Job group for statement 11:\nDESCRIBE EXTENDED syndb1.t_manag_part_delta: Compute snapshot for version: 1","displayName":"toString at String.java:2994","jobGroup":"11","jobId":18,"killedTasksSummary":{},"name":"toString at String.java:2994","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":2,"numSkippedTasks":52,"numTasks":53,"rowCount":50,"stageIds":[27,28,26],"status":"SUCCEEDED","submissionTime":"2023-09-25T14:14:53.945GMT","usageDescription":""},{"completionTime":"2023-09-25T14:14:53.922GMT","dataRead":5607,"dataWritten":4469,"description":"Delta: Job group for statement 11:\nDESCRIBE EXTENDED syndb1.t_manag_part_delta: Compute snapshot for version: 1","displayName":"toString at String.java:2994","jobGroup":"11","jobId":17,"killedTasksSummary":{},"name":"toString at String.java:2994","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":50,"numCompletedStages":1,"numCompletedTasks":50,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":1,"numSkippedTasks":2,"numTasks":52,"rowCount":60,"stageIds":[24,25],"status":"SUCCEEDED","submissionTime":"2023-09-25T14:14:53.183GMT","usageDescription":""},{"completionTime":"2023-09-25T14:14:51.928GMT","dataRead":6986,"dataWritten":5607,"description":"Delta: Job group for statement 11:\nDESCRIBE EXTENDED syndb1.t_manag_part_delta: Compute snapshot for version: 1","displayName":"toString at String.java:2994","jobGroup":"11","jobId":16,"killedTasksSummary":{},"name":"toString at String.java:2994","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":2,"numCompletedStages":1,"numCompletedTasks":2,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":2,"rowCount":20,"stageIds":[23],"status":"SUCCEEDED","submissionTime":"2023-09-25T14:14:51.444GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":3,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":11},"text/plain":["StatementMeta(, 10d88e4e-d3dd-415c-93ed-45b9586d38ca, 11, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.synapse.sparksql-result+json":{"data":[["CustomerKey","string",""],["WWICustomerID","string",""],["Customer","string",""],["BillToCustomer","string",""],["Category","string",""],["BuyingGroup","string",""],["PrimaryContact","string",""],["PostalCode","string",""],["ValidFrom","string",""],["ValidTo","string",""],["LineageKey","string",""],["","",""],["# Partitioning","",""],["Part 0","Category",""],["","",""],["# Detailed Table Information","",""],["Name","syndb1.t_manag_part_delta",""],["Location","abfss://default@stmurggudata.dfs.core.windows.net/synapse/workspaces/syn-murggu-data/warehouse/syndb1.db/t_manag_part_delta",""],["Provider","delta",""],["Owner","trusted-service-user",""],["External","true",""],["Table Properties","[delta.minReaderVersion=1,delta.minWriterVersion=2]",""]],"schema":{"fields":[{"metadata":{"comment":"name of the column"},"name":"col_name","nullable":false,"type":"string"},{"metadata":{"comment":"data type of the column"},"name":"data_type","nullable":false,"type":"string"},{"metadata":{"comment":"comment of the column"},"name":"comment","nullable":true,"type":"string"}],"type":"struct"}},"text/plain":["<Spark SQL result set with 22 rows and 3 fields>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["%%sql\n","DESCRIBE EXTENDED syndb1.t_manag_part_delta"]},{"cell_type":"code","execution_count":12,"id":"d4ac6f99-425d-4606-8cde-e087026ff652","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-09-25T14:16:37.3904199Z","execution_start_time":"2023-09-25T14:16:36.2626361Z","livy_statement_state":"available","parent_msg_id":"6d21fd43-bd75-4a10-921d-ed2e67291cb8","queued_time":"2023-09-25T14:16:35.2185322Z","session_id":"10d88e4e-d3dd-415c-93ed-45b9586d38ca","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-09-25T14:16:36.898GMT","dataRead":0,"dataWritten":0,"description":"Job group for statement 15:\nspark.catalog.listTables()","displayName":"hasNext at NativeMethodAccessorImpl.java:0","jobGroup":"15","jobId":19,"killedTasksSummary":{},"name":"hasNext at NativeMethodAccessorImpl.java:0","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":0,"stageIds":[29],"status":"SUCCEEDED","submissionTime":"2023-09-25T14:16:36.883GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":15},"text/plain":["StatementMeta(, 10d88e4e-d3dd-415c-93ed-45b9586d38ca, 15, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[Table(name='students_3', database='synapse', description=None, tableType='MANAGED', isTemporary=False)]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["%%pyspark\n","spark.catalog.listTables()"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","name":"synapse_pyspark"},"language_info":{"name":"scala"},"microsoft":{"host":{"synapse_widget":{"state":{},"token":"c71ec2fe-4d5f-47a7-81d5-cef34f5f506f"}},"language":"scala","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"synapse_widget":{"state":{},"version":"0.1"},"trident":{"lakehouse":{"default_lakehouse":"255fdd58-6a1d-40b6-86f7-76102aab0fbd","default_lakehouse_name":"synapse","default_lakehouse_workspace_id":"d3de3f63-266f-454c-87e1-5c7c598a41dd","known_lakehouses":[{"id":"255fdd58-6a1d-40b6-86f7-76102aab0fbd"}]}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
